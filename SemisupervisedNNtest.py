import time
import streamlit as st
import os
import numpy as np
import pandas as pd
import random
import mlflow
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras import layers, optimizers
from sklearn.model_selection import train_test_split, StratifiedKFold
from tensorflow.keras.models import Sequential
from tensorflow import keras




def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is not None:
        img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
        img = img.resize((28, 28)).convert("L")  # Resize vÃ  chuyá»ƒn thÃ nh grayscale
        img = np.array(img, dtype=np.float32) / 255.0  # Chuáº©n hÃ³a vá» [0, 1]
        return img.reshape(1, -1)  # Chuyá»ƒn thÃ nh vector 1D
    return None

def load_mnist_data():
    X = np.load("data/X_test.npy")
    y = np.load("data/y_test.npy")
    return X, y






def data_preparation():
    # Äá»c dá»¯ liá»‡u
    X, y = load_mnist_data()
    X = X.reshape(X.shape[0], -1)  # Chuyá»ƒn áº£nh vá» vector 1D
    # total_samples = X.shape[0] 

    # Cho phÃ©p ngÆ°á»i dÃ¹ng chá»n tá»· lá»‡ validation vÃ  test
    test_size = st.slider("ğŸ”¹ Chá»n % tá»· lá»‡ táº­p test", min_value=10, max_value=50, value=20, step=1) / 100

    # Táº¡o vÃ¹ng trá»‘ng Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£
    result_placeholder = st.empty()
    # Táº¡o nÃºt "LÆ°u Dá»¯ Liá»‡u"
    if st.button("XÃ¡c Nháº­n & LÆ°u Dá»¯ Liá»‡u"):
        
        # PhÃ¢n chia dá»¯ liá»‡u
        X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(X, y, test_size=test_size, random_state=42)
        
        # Láº¥y 1% sá»‘ lÆ°á»£ng áº£nh cho má»—i class (0-9) Ä‘á»ƒ lÃ m táº­p dá»¯ liá»‡u train ban Ä‘áº§u
        train_indices = []
        for i in range(10):
            class_indices = np.where(y_train_data == i)[0]
            num_samples = int(0.01 * len(class_indices))
            indices = np.random.choice(class_indices, num_samples, replace=False)
            train_indices.extend(indices)

        X_train_initial = X_train_data[train_indices]
        y_train_initial = y_train_data[train_indices]

        # Chuyá»ƒn 99% cÃ²n láº¡i sang táº­p val
        val_indices = np.setdiff1d(np.arange(len(X_train_data)), train_indices)
        X_val_data = X_train_data[val_indices]
        y_val_data = y_train_data[val_indices]


        # TÃ­nh tá»· lá»‡ thá»±c táº¿ cá»§a tá»«ng táº­p
        total_samples = X.shape[0]
        test_percent = (X_test_data.shape[0] / total_samples) * 100
        train_percent = (X_train_initial.shape[0] / total_samples) * 100
        val_percent = (X_val_data.shape[0] / total_samples) * 100

        # LÆ°u dá»¯ liá»‡u vÃ o session_state
        st.session_state["X_train"] = X_train_initial
        st.session_state["y_train"] = y_train_initial
        st.session_state["X_val"] = X_val_data
        st.session_state["y_val"] = y_val_data
        st.session_state["X_test"] = X_test_data
        st.session_state["y_test"] = y_test_data
        
        # # Ghi log cho quÃ¡ trÃ¬nh phÃ¢n chia dá»¯ liá»‡u
        # mlflow.log_param("test_size", test_size)
        # mlflow.log_metric("test_percent", test_percent)
        # mlflow.log_metric("train_percent", train_percent)
        # mlflow.log_metric("val_percent", val_percent)
        # with result_placeholder:
        # Hiá»ƒn thá»‹ káº¿t quáº£
        st.write(f"ğŸ“Š **Tá»· lá»‡ phÃ¢n chia**: Test={test_percent:.0f}%, Train={train_percent:.0f}%, Val={val_percent:.0f}%")
        st.write("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  chia tÃ¡ch.")
        st.write(f"ğŸ”¹ KÃ­ch thÆ°á»›c táº­p huáº¥n luyá»‡n ban Ä‘áº§u: `{X_train_initial.shape}`")
        st.write(f"ğŸ”¹ KÃ­ch thÆ°á»›c táº­p kiá»ƒm tra: `{X_test_data.shape}`")
        st.write(f"ğŸ”¹ KÃ­ch thÆ°á»›c táº­p validation: `{X_val_data.shape}`")

        # Táº¡o biá»ƒu Ä‘á»“ sá»‘ lÆ°á»£ng dá»¯ liá»‡u cá»§a má»—i nhÃ£n trong táº­p train
        unique_labels, counts = np.unique(y_train_initial, return_counts=True)
        fig, ax = plt.subplots()
        ax.bar(unique_labels, counts)
        ax.set_xlabel('NhÃ£n')
        ax.set_ylabel('Sá»‘ lÆ°á»£ng')
        ax.set_title('PhÃ¢n phá»‘i sá»‘ lÆ°á»£ng dá»¯ liá»‡u trong táº­p train')
        ax.set_xticks(unique_labels)
        st.pyplot(fig)





def learning_model():
    # Láº¥y dá»¯ liá»‡u tá»« session_state
    X_train = st.session_state["X_train"]
    X_val = st.session_state["X_val"]
    X_test = st.session_state["X_test"]
    y_train = st.session_state["y_train"]
    y_val = st.session_state["y_val"]
    y_test = st.session_state["y_test"]

    # Lá»±a chá»n tham sá»‘ huáº¥n luyá»‡n
    num_k_folds = st.slider("Sá»‘ fold cho Cross-Validation:", 3, 10, 5)
    num_layers = st.slider("Sá»‘ lá»›p áº©n:", 1, 5, 2)
    epochs = st.slider("Sá»‘ láº§n láº·p tá»‘i Ä‘a", 2, 50, 5)
    learning_rate_init = st.slider("Tá»‘c Ä‘á»™ há»c", 0.001, 0.1, 0.01, step=0.001, format="%.3f")
    threshold = st.slider("Threshold", min_value=0.0, max_value=1.0, value=0.6, step=0.01)
    iteration = st.slider("Sá»‘ láº§n láº·p tá»‘i Ä‘a", 1, 10, 5)
    activation = st.selectbox("HÃ m kÃ­ch hoáº¡t:", ["relu", "sigmoid", "tanh"])
    num_neurons = st.selectbox("Sá»‘ neuron má»—i lá»›p:", [32, 64, 128, 256], index=0)
    optimizer = st.selectbox("Chá»n hÃ m tá»‘i Æ°u", ["adam", "sgd", "lbfgs"])
    loss_fn = "sparse_categorical_crossentropy"
    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run")
    st.session_state['run_name'] = run_name

    if st.button("â¹ï¸ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        with st.spinner("ğŸ”„ Äang huáº¥n luyá»‡n..."):
            mlflow.start_run(run_name=run_name)

            # Ghi log cÃ¡c tham sá»‘
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "k_folds": num_k_folds,
                "epochs": epochs,
                "learning_rate": learning_rate_init,
                "threshold": threshold,
                "max_iterations": iteration
            })

            # Táº¡o mÃ´ hÃ¬nh Neural Network
            cnn = keras.Sequential([
                layers.Input(shape=(X_train.shape[1],)),
                *[layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)],
                layers.Dense(10, activation="softmax")
            ])

            # Chá»n optimizer
            if optimizer == "adam":
                opt = keras.optimizers.Adam(learning_rate=learning_rate_init)
            elif optimizer == "sgd":
                opt = keras.optimizers.SGD(learning_rate=learning_rate_init)
            else:
                opt = keras.optimizers.RMSprop(learning_rate=learning_rate_init)

            cnn.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

            # Khá»Ÿi táº¡o cÃ¡c biáº¿n
            accuracies, losses = [], []
            start_time = time.time()
            iteration_count = 0

            if len(X_train) == 0 or len(y_train) == 0:
                st.error("âŒ Táº­p huáº¥n luyá»‡n rá»—ng!")
                mlflow.end_run()
                return
            # VÃ²ng láº·p huáº¥n luyá»‡n vá»›i Pseudo-Labeling
            for iter_idx in range(iteration):
                iteration_count += 1
                st.write(f"**Láº§n láº·p thá»© {iteration_count}:**")
                k_folds = min(num_k_folds, max(2, int(5000 / len(X_train))))
                progress_bar = st.progress(0)
                progress_text = st.empty()

                # Cross-validation vá»›i StratifiedKFold
                kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
                fold_count = 0
                for i, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):
                    fold_count += 1
                    X_k_train, X_k_val = X_train[train_idx], X_train[val_idx]
                    y_k_train, y_k_val = y_train[train_idx], y_train[val_idx]

                    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
                    history = cnn.fit(
                        X_k_train, y_k_train,
                        epochs=epochs,
                        validation_data=(X_k_val, y_k_val),
                        verbose=0,  # Táº¯t log chi tiáº¿t Ä‘á»ƒ trÃ¡nh lÃ m cháº­m Streamlit
                        batch_size=num_neurons  # ThÃªm batch_size Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t
                    )

                    accuracies.append(history.history["val_accuracy"][-1])
                    losses.append(history.history["val_loss"][-1])

                    # Cáº­p nháº­t tiáº¿n trÃ¬nh
                    progress = i
                    progress_bar.progress(progress)
                    progress_text.text(f"ï¸ğŸ¯ Tiáº¿n trÃ¬nh huáº¥n luyá»‡n: {int(progress * 100)}%")

                # Dá»± Ä‘oÃ¡n trÃªn táº­p validation Ä‘á»ƒ gÃ¡n nhÃ£n giáº£ (Pseudo-Labeling)
                if len(X_val) > 0:
                    y_pred = cnn.predict(X_val, verbose=0)
                    y_pred_class = np.argmax(y_pred, axis=1)
                    max_probs = np.max(y_pred, axis=1)

                    # GÃ¡n nhÃ£n giáº£ dá»±a trÃªn ngÆ°á»¡ng
                    pseudo_labels = np.where(max_probs >= threshold, y_pred_class, -1)
                    confident_mask = max_probs >= threshold

                    X_confident = X_val[confident_mask]
                    y_confident = pseudo_labels[confident_mask]

                    # Cáº­p nháº­t táº­p huáº¥n luyá»‡n vÃ  táº­p validation
                    if len(X_confident) > 0:
                        X_train = np.concatenate((X_train, X_confident), axis=0)
                        y_train = np.concatenate((y_train, y_confident), axis=0)
                        X_val = X_val[~confident_mask]
                        y_val = y_val[~confident_mask]
                    else:
                        st.write(f"ğŸ”¹ VÃ²ng {iter_idx + 1}: KhÃ´ng cÃ³ máº«u nÃ o vÆ°á»£t ngÆ°á»¡ng {threshold}. Dá»«ng láº¡i.")
                        break

                    # Äiá»u kiá»‡n dá»«ng
                    if len(X_val) == 0:
                        st.write("âœ… ÄÃ£ gÃ¡n nhÃ£n háº¿t táº­p unlabeled!")
                        break
                    elif len(X_confident) < 10:
                        st.write(f"ğŸ”¹ VÃ²ng {iter_idx + 1}: Sá»‘ máº«u gÃ¡n nhÃ£n quÃ¡ Ã­t ({len(X_confident)}). Dá»«ng láº¡i.")
                        break
                else:
                    st.write("âœ… KhÃ´ng cÃ²n dá»¯ liá»‡u unlabeled Ä‘á»ƒ gÃ¡n nhÃ£n!")
                    break

            # Káº¿t thÃºc huáº¥n luyá»‡n
            elapsed_time = time.time() - start_time
            avg_val_accuracy = np.mean(accuracies) if accuracies else 0
            avg_val_loss = np.mean(losses) if losses else 0

            # ÄÃ¡nh giÃ¡ trÃªn táº­p test
            test_loss, test_accuracy = cnn.evaluate(X_test, y_test, verbose=0)

            # Ghi log káº¿t quáº£
            mlflow.log_metrics({
                "avg_val_accuracy": avg_val_accuracy,
                "avg_val_loss": avg_val_loss,
                "test_accuracy": test_accuracy,
                "test_loss": test_loss,
                "elapsed_time": elapsed_time
            })

            mlflow.end_run()

            # LÆ°u mÃ´ hÃ¬nh vÃ  hiá»ƒn thá»‹ káº¿t quáº£
            st.session_state["selected_model_type"] = "Neural Network"
            st.session_state["trained_model"] = cnn
            st.success(f"âœ… Huáº¥n luyá»‡n hoÃ n táº¥t trong {elapsed_time:.2f} giÃ¢y!")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")

            # Váº½ biá»ƒu Ä‘á»“ Loss vÃ  Accuracy
            st.markdown("#### ğŸ“ˆ Biá»ƒu Ä‘á»“ Accuracy vÃ  Loss")
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
            ax1.plot(history.history['loss'], label='Train Loss', color='blue')
            ax1.plot(history.history['val_loss'], label='Test Loss', color='orange')
            ax1.set_title('Loss')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.legend()

            ax2.plot(history.history['accuracy'], label='Train Accuracy', color='blue')
            ax2.plot(history.history['val_accuracy'], label='Test Accuracy', color='orange')
            ax2.set_title('Accuracy')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Accuracy')
            ax2.legend()

            st.pyplot(fig)








def run_PseudoLabellingt_app():
    

    # @st.cache_data  # LÆ°u cache Ä‘á»ƒ trÃ¡nh load láº¡i dá»¯ liá»‡u má»—i láº§n cháº¡y láº¡i Streamlit
    # def get_sampled_pixels(images, sample_size=100_000):
    #     return np.random.choice(images.flatten(), sample_size, replace=False)

    # @st.cache_data  # Cache danh sÃ¡ch áº£nh ngáº«u nhiÃªn
    # def get_random_indices(num_images, total_images):
    #     return np.random.randint(0, total_images, size=num_images)

    # # Cáº¥u hÃ¬nh Streamlit    
    # # st.set_page_config(page_title="PhÃ¢n loáº¡i áº£nh", layout="wide")
    # # Äá»‹nh nghÄ©a hÃ m Ä‘á»ƒ Ä‘á»c file .idx
    # def load_mnist_images(filename):
    #     with open(filename, 'rb') as f:
    #         magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
    #         images = np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)
    #     return images

    # def load_mnist_labels(filename):
    #     with open(filename, 'rb') as f:
    #         magic, num = struct.unpack('>II', f.read(8))
    #         labels = np.fromfile(f, dtype=np.uint8)
    #     return labels

    mlflow_tracking_uri = st.secrets["MLFLOW_TRACKING_URI"]
    mlflow_username = st.secrets["MLFLOW_TRACKING_USERNAME"]
    mlflow_password = st.secrets["MLFLOW_TRACKING_PASSWORD"]
    
    # Thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng
    os.environ["MLFLOW_TRACKING_URI"] = mlflow_tracking_uri
    os.environ["MLFLOW_TRACKING_USERNAME"] = mlflow_username
    os.environ["MLFLOW_TRACKING_PASSWORD"] = mlflow_password
    
    # Thiáº¿t láº­p MLflow (Äáº·t sau khi mlflow_tracking_uri Ä‘Ã£ cÃ³ giÃ¡ trá»‹)
    mlflow.set_tracking_uri(mlflow_tracking_uri)

    # Äá»c dá»¯ liá»‡u
    X_data, y_data = load_mnist_data()

    # total_samples = X.shape[0] # Tá»•ng sá»‘ máº«u

    # # Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c file MNIST
    # dataset_path = os.path.dirname(os.path.abspath(__file__)) 
    # train_images_path = os.path.join(dataset_path, "train-images.idx3-ubyte")
    # train_labels_path = os.path.join(dataset_path, "train-labels.idx1-ubyte")
    # test_images_path = os.path.join(dataset_path, "t10k-images.idx3-ubyte")
    # test_labels_path = os.path.join(dataset_path, "t10k-labels.idx1-ubyte")

    # # Táº£i dá»¯ liá»‡u
    # train_images = load_mnist_images(train_images_path)
    # train_labels = load_mnist_labels(train_labels_path)
    # test_images = load_mnist_images(test_images_path)
    # test_labels = load_mnist_labels(test_labels_path)

    # Giao diá»‡n Streamlit
    st.title("ğŸ“¸ PhÃ¢n loáº¡i áº£nh MNIST vá»›i Streamlit")
    tabs = st.tabs([
        "ThÃ´ng tin dá»¯ liá»‡u",
        "ThÃ´ng tin",
        "Chuáº©n bá»‹ dá»¯ liá»‡u",
        "Huáº¥n luyá»‡n mÃ´ hÃ¬nh",
        "Demo dá»± Ä‘oÃ¡n file áº£nh",
        "Demo dá»± Ä‘oÃ¡n Viáº¿t Tay",
        "ThÃ´ng tin & Mlflow",
    ])
    # tab_info, tab_load, tab_preprocess, tab_split,  tab_demo, tab_log_info = tabs
    tab_info,tab_note, tab_data ,tab_preprocess,  tab_demo, tab_demo_2 ,tab_mlflow= tabs






    # with st.expander("ğŸ–¼ï¸ Dá»¯ liá»‡u ban Ä‘áº§u", expanded=True):
    with tab_info:
        with st.expander("**ThÃ´ng tin dá»¯ liá»‡u**", expanded=True):
            st.markdown(
                '''
                **MNIST** lÃ  phiÃªn báº£n Ä‘Æ°á»£c chá»‰nh sá»­a tá»« bá»™ dá»¯ liá»‡u NIST gá»‘c cá»§a Viá»‡n TiÃªu chuáº©n vÃ  CÃ´ng nghá»‡ Quá»‘c gia Hoa Ká»³.  
                Bá»™ dá»¯ liá»‡u ban Ä‘áº§u gá»“m cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« nhÃ¢n viÃªn bÆ°u Ä‘iá»‡n vÃ  há»c sinh trung há»c.  

                CÃ¡c nhÃ  nghiÃªn cá»©u **Yann LeCun, Corinna Cortes, vÃ  Christopher Burges** Ä‘Ã£ xá»­ lÃ½, chuáº©n hÃ³a vÃ  chuyá»ƒn Ä‘á»•i bá»™ dá»¯ liá»‡u nÃ y thÃ nh **MNIST** Ä‘á»ƒ dá»… dÃ ng sá»­ dá»¥ng hÆ¡n cho cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay.
                '''
            )
            # image = Image.open(r'C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\App\image.png')

            # Gáº¯n áº£nh vÃ o Streamlit vÃ  chá»‰nh kÃ­ch thÆ°á»›c
            # st.image(image, caption='MÃ´ táº£ áº£nh', width=600) 
            # Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u
        with st.expander("**Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u**", expanded=True):
            st.markdown(
                '''
                - **Sá»‘ lÆ°á»£ng áº£nh:** 70.000 áº£nh chá»¯ sá»‘ viáº¿t tay  
                - **KÃ­ch thÆ°á»›c áº£nh:** Má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c 28x28 pixel  
                - **CÆ°á»ng Ä‘á»™ Ä‘iá»ƒm áº£nh:** Tá»« 0 (mÃ u Ä‘en) Ä‘áº¿n 255 (mÃ u tráº¯ng)  
                - **Dá»¯ liá»‡u nhÃ£n:** Má»—i áº£nh Ä‘i kÃ¨m vá»›i má»™t nhÃ£n sá»‘ tá»« 0 Ä‘áº¿n 9  
                '''
            )
            st.write(f"ğŸ” Sá»‘ lÆ°á»£ng áº£nh huáº¥n luyá»‡n: `{X_data.shape[0]}`")
            st.write(f"ğŸ” Sá»‘ lÆ°á»£ng áº£nh kiá»ƒm tra: `{y_data.shape[0]}`")

        with st.expander("**Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9 trong táº­p huáº¥n luyá»‡n**", expanded=True):
            label_counts = pd.Series(y_data).value_counts().sort_index()

            # # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ cá»™t
            # st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng chá»¯ sá»‘")
            # st.bar_chart(label_counts)

            # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u dÆ°á»›i biá»ƒu Ä‘á»“
            st.subheader("ğŸ“‹ Sá»‘ lÆ°á»£ng máº«u cho tá»«ng chá»¯ sá»‘")
            df_counts = pd.DataFrame({"Chá»¯ sá»‘": label_counts.index, "Sá»‘ lÆ°á»£ng máº«u": label_counts.values})
            st.dataframe(df_counts)


            st.subheader("Chá»n ngáº«u nhiÃªn 10 áº£nh tá»« táº­p huáº¥n luyá»‡n Ä‘á»ƒ hiá»ƒn thá»‹")
            num_images = 10
            random_indices = random.sample(range(len(X_data)), num_images)
            fig, axes = plt.subplots(1, num_images, figsize=(10, 5))

            for ax, idx in zip(axes, random_indices):
                ax.imshow(X_data[idx], cmap='gray')
                ax.axis("off")
                ax.set_title(f"Label: {y_data[idx]}")

            st.pyplot(fig)
        with st.expander("**Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u**", expanded=True):    
            # Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u
            st.write("ğŸ” HÃ¬nh dáº¡ng táº­p dá»¯ liá»‡u:", X_data.shape)


    with tab_note:
        with st.expander("**ThÃ´ng tin mÃ´ hÃ¬nh**", expanded=True):
        # Assume model_option1 is selected from somewhere in the app
            st.markdown("""
                    ### Neural Network (NN)
                    """) 
            st.markdown("---")        
            st.markdown("""            
            ### KhÃ¡i Niá»‡m:  
            **Neural Network (NN)**:
            - LÃ  má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n láº¥y cáº£m há»©ng tá»« cáº¥u trÃºc vÃ  chá»©c nÄƒng cá»§a máº¡ng lÆ°á»›i tháº§n kinh sinh há»c. NÃ³ Ä‘Æ°á»£c táº¡o thÃ nh tá»« cÃ¡c nÃºt káº¿t ná»‘i vá»›i nhau, hay cÃ²n gá»i lÃ  nÆ¡-ron nhÃ¢n táº¡o, Ä‘Æ°á»£c sáº¯p xáº¿p thÃ nh cÃ¡c lá»›p.
            - Ã tÆ°á»Ÿng chÃ­nh cá»§a **Neural Network** lÃ  táº¡o ra má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n cÃ³ kháº£ nÄƒng há»c há»i vÃ  xá»­ lÃ½ thÃ´ng tin giá»‘ng nhÆ° bá»™ nÃ£o con ngÆ°á»i.
            """)

            st.markdown("---")        
                       
            st.write("### MÃ´ HÃ¬nh Tá»•ng QuÃ¡t:")   
            st.image("imgnn/modelnn.png",use_container_width ="auto")
            st.markdown(""" 
            - Layer Ä‘áº§u tiÃªn lÃ  input layer, cÃ¡c layer á»Ÿ giá»¯a Ä‘Æ°á»£c gá»i lÃ  hidden layer, layer cuá»‘i cÃ¹ng Ä‘Æ°á»£c gá»i lÃ  output layer. CÃ¡c hÃ¬nh trÃ²n Ä‘Æ°á»£c gá»i lÃ  node.
            - Má»—i mÃ´ hÃ¬nh luÃ´n cÃ³ 1 input layer, 1 output layer, cÃ³ thá»ƒ cÃ³ hoáº·c khÃ´ng cÃ¡c hidden layer. Tá»•ng sá»‘ layer trong mÃ´ hÃ¬nh Ä‘Æ°á»£c quy Æ°á»›c lÃ  sá»‘ layer - 1 (KhÃ´ng tÃ­nh input layer).
            - Má»—i node trong hidden layer vÃ  output layer :
                - LiÃªn káº¿t vá»›i táº¥t cáº£ cÃ¡c node á»Ÿ layer trÆ°á»›c Ä‘Ã³ vá»›i cÃ¡c há»‡ sá»‘ w riÃªng.
                - Má»—i node cÃ³ 1 há»‡ sá»‘ bias b riÃªng.
                - Diá»…n ra 2 bÆ°á»›c: tÃ­nh tá»•ng linear vÃ  Ã¡p dá»¥ng activation function.
            """)

            st.markdown("---")          
            st.markdown("""
            ### NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng:  
            - Dá»¯ liá»‡u Ä‘áº§u vÃ o Ä‘Æ°á»£c Ä‘Æ°a vÃ o lá»›p Ä‘áº§u vÃ o.
            - Má»—i nÆ¡-ron trong lá»›p áº©n nháº­n tÃ­n hiá»‡u tá»« cÃ¡c nÆ¡-ron á»Ÿ lá»›p trÆ°á»›c Ä‘Ã³, xá»­ lÃ½ tÃ­n hiá»‡u vÃ  chuyá»ƒn tiáº¿p káº¿t quáº£ Ä‘áº¿n cÃ¡c nÆ¡-ron á»Ÿ lá»›p tiáº¿p theo.
            - QuÃ¡ trÃ¬nh nÃ y tiáº¿p tá»¥c cho Ä‘áº¿n khi dá»¯ liá»‡u Ä‘áº¿n lá»›p Ä‘áº§u ra.
            - Káº¿t quáº£ Ä‘áº§u ra Ä‘Æ°á»£c táº¡o ra dá»±a trÃªn cÃ¡c tÃ­n hiá»‡u nháº­n Ä‘Æ°á»£c tá»« lá»›p áº©n cuá»‘i cÃ¹ng.
            """)           
            st.markdown("---")
            st.markdown("""  
            ### Ãp dá»¥ng vÃ o ngá»¯ cáº£nh Neural Network vá»›i MNIST:  
            - **MNIST (Modified National Institute of Standards and Technology database)** lÃ  má»™t bá»™ dá»¯ liá»‡u kinh Ä‘iá»ƒn trong lÄ©nh vá»±c há»c mÃ¡y, Ä‘áº·c biá»‡t lÃ  trong viá»‡c Ã¡p dá»¥ng máº¡ng nÆ¡-ron. NÃ³ bao gá»“m 70.000 áº£nh xÃ¡m cá»§a chá»¯ sá»‘ viáº¿t tay (tá»« 0 Ä‘áº¿n 9), Ä‘Æ°á»£c chia thÃ nh 60.000 áº£nh huáº¥n luyá»‡n vÃ  10.000 áº£nh kiá»ƒm tra.
            - Má»¥c tiÃªu cá»§a bÃ i toÃ¡n lÃ  phÃ¢n loáº¡i chÃ­nh xÃ¡c chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9 dá»±a trÃªn áº£nh Ä‘áº§u vÃ o.
            - CÃ³ nhiá»u cÃ¡ch Ä‘á»ƒ Ã¡p dá»¥ng máº¡ng nÆ¡-ron cho bÃ i toÃ¡n phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay trÃªn MNIST. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ phÆ°Æ¡ng phÃ¡p phá»• biáº¿n:
                - **Multi-Layer Perceptron (MLP)**: Má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sÃ¢u vá»›i nhiá»u lá»›p áº©n.
                - **Convolutional Neural Network (CNN)**: Má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sÃ¢u Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho viá»‡c xá»­ lÃ½ áº£nh.
                - **Recurrent Neural Network (RNN)**: Má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sÃ¢u Ä‘Æ°á»£c thiáº¿t káº¿ cho dá»¯ liá»‡u chuá»—i.
            """)

    


    # Chuáº©n bá»‹ dá»¯ liá»‡u
    with tab_data:
        with st.expander("**Chuáº©n bá»‹ dá»¯ liá»‡u**", expanded=True):
            st.write("ğŸ” **Chuáº©n bá»‹ dá»¯ liá»‡u cho mÃ´ hÃ¬nh**")
            data_preparation()  
        





    # 3ï¸âƒ£ HUáº¤N LUYá»†N MÃ” HÃŒNH
    with tab_preprocess:
        with st.expander("**Huáº¥n luyá»‡n Neural Network**", expanded=True):
        
            # Cáº­p nháº­t dá»¯ liá»‡u
            learning_model()
                
                    





    with tab_demo:
        with st.expander("**Dá»± Ä‘oÃ¡n káº¿t quáº£**", expanded=True):
            st.write("**Dá»± Ä‘oÃ¡n trÃªn áº£nh do ngÆ°á»i dÃ¹ng táº£i lÃªn**")
            if "trained_model" not in st.session_state:
                st.warning("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n.")
            else:
                best_model = st.session_state["trained_model"]
                st.write(f"MÃ´ hÃ¬nh Ä‘ang sá»­ dá»¥ng: Neural Network")

                uploaded_file = st.file_uploader("ğŸ“‚ Chá»n má»™t áº£nh", type=["png", "jpg", "jpeg"])
                if uploaded_file:
                    image = Image.open(uploaded_file).convert("L")
                    image = np.array(image.resize((28, 28)), dtype=np.float32) / 255.0  # Normalize to [0, 1]
                    image = image.reshape(1, -1)  # Shape: (1, 784)

                    prediction = best_model.predict(image)[0]
                    st.image(uploaded_file, caption="ğŸ“· áº¢nh Ä‘Ã£ táº£i lÃªn", width=150)
                    st.success(f"Dá»± Ä‘oÃ¡n: {np.argmax(prediction)} vá»›i xÃ¡c suáº¥t {np.max(prediction):.2f}")







    with tab_demo_2:   
        with st.expander("**Dá»± Ä‘oÃ¡n káº¿t quáº£**", expanded=True):
            st.write("**Dá»± Ä‘oÃ¡n trÃªn áº£nh do ngÆ°á»i dÃ¹ng táº£i lÃªn**")

            # Kiá»ƒm tra xem mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  lÆ°u káº¿t quáº£ chÆ°a
            if "selected_model_type" not in st.session_state or "trained_model" not in st.session_state:
                st.warning("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c khi dá»± Ä‘oÃ¡n.")
            else:
                best_model_name = st.session_state.selected_model_type
                best_model = st.session_state.trained_model

                st.write(f"MÃ´ hÃ¬nh Ä‘ang sá»­ dá»¥ng: `{best_model_name}`")
                # st.write(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm tra: `{st.session_state.get('test_accuracy', 'N/A'):.4f}`")

                # ğŸ†• Cáº­p nháº­t key cho canvas khi nháº¥n "Táº£i láº¡i"
                # if "key_value" not in st.session_state:
                #     st.session_state.key_value = str(random.randint(0, 1000000))

                # if st.button("ğŸ”„ Táº£i láº¡i"):
                #     try:
                #         st.session_state.key_value = str(random.randint(0, 1000000))
                #     except Exception as e:
                #         st.error(f"Cáº­p nháº­t key khÃ´ng thÃ nh cÃ´ng: {str(e)}")
                #         st.stop()
                st.session_state.key_value = str(random.randint(0, 1000000))

                # âœï¸ Váº½ dá»¯ liá»‡u
                canvas_result = st_canvas(
                    fill_color="black",
                    stroke_width=10,
                    stroke_color="white",
                    background_color="black",
                    height=150,
                    width=150,
                    drawing_mode="freedraw",
                    key=st.session_state.key_value,
                    update_streamlit=True
                ) 

                if st.button("Dá»± Ä‘oÃ¡n"):
                    img = preprocess_canvas_image(canvas_result)

                    if img is not None:
                        X_train = st.session_state["X_train"]
                        # Hiá»ƒn thá»‹ áº£nh sau xá»­ lÃ½
                        st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)

                        # Dá»± Ä‘oÃ¡n
                        prediction = best_model.predict(img)[0]

                        st.success(f"Dá»± Ä‘oÃ¡n: {np.argmax(prediction)} vá»›i xÃ¡c suáº¥t {np.max(prediction)*100:.2f}%")
                    else:
                        st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")







    with tab_mlflow:
        st.header("ThÃ´ng tin Huáº¥n luyá»‡n & MLflow UI")
        try:
            client = MlflowClient()
            experiment_name = "Classification"
    
            # Kiá»ƒm tra náº¿u experiment Ä‘Ã£ tá»“n táº¡i
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment is None:
                experiment_id = client.create_experiment(experiment_name)
                st.success(f"Experiment má»›i Ä‘Æ°á»£c táº¡o vá»›i ID: {experiment_id}")
            else:
                experiment_id = experiment.experiment_id
                st.info(f"Äang sá»­ dá»¥ng experiment ID: {experiment_id}")
    
            mlflow.set_experiment(experiment_name)
    
            # Truy váº¥n cÃ¡c run trong experiment
            runs = client.search_runs(experiment_ids=[experiment_id])
    
            # 1) Chá»n vÃ  Ä‘á»•i tÃªn Run Name
            st.subheader("Äá»•i tÃªn Run")
            if runs:
                run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}"
                               for run in runs}
                selected_run_id_for_rename = st.selectbox("Chá»n Run Ä‘á»ƒ Ä‘á»•i tÃªn:", 
                                                          options=list(run_options.keys()), 
                                                          format_func=lambda x: run_options[x])
                new_run_name = st.text_input("Nháº­p tÃªn má»›i cho Run:", 
                                             value=run_options[selected_run_id_for_rename].split(" - ")[0])
                if st.button("Cáº­p nháº­t tÃªn Run"):
                    if new_run_name.strip():
                        client.set_tag(selected_run_id_for_rename, "mlflow.runName", new_run_name.strip())
                        st.success(f"ÄÃ£ cáº­p nháº­t tÃªn Run thÃ nh: {new_run_name.strip()}")
                    else:
                        st.warning("Vui lÃ²ng nháº­p tÃªn má»›i cho Run.")
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘Æ°á»£c log.")
    
            # 2) XÃ³a Run
            st.subheader("Danh sÃ¡ch Run")
            if runs:
                selected_run_id_to_delete = st.selectbox("", 
                                                         options=list(run_options.keys()), 
                                                         format_func=lambda x: run_options[x])
                if st.button("XÃ³a Run", key="delete_run"):
                    client.delete_run(selected_run_id_to_delete)
                    st.success(f"ÄÃ£ xÃ³a Run {run_options[selected_run_id_to_delete]} thÃ nh cÃ´ng!")
                    st.experimental_rerun()  # Tá»± Ä‘á»™ng lÃ m má»›i giao diá»‡n
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘á»ƒ xÃ³a.")
    
            # 3) Danh sÃ¡ch cÃ¡c thÃ­ nghiá»‡m
            st.subheader("Danh sÃ¡ch cÃ¡c Run Ä‘Ã£ log")
            if runs:
                selected_run_id = st.selectbox("Chá»n Run Ä‘á»ƒ xem chi tiáº¿t:", 
                                               options=list(run_options.keys()), 
                                               format_func=lambda x: run_options[x])
    
                # 4) Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t cá»§a Run Ä‘Æ°á»£c chá»n
                selected_run = client.get_run(selected_run_id)
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")
    
                st.markdown("### Tham sá»‘ Ä‘Ã£ log")
                st.json(selected_run.data.params)
    
                st.markdown("### Chá»‰ sá»‘ Ä‘Ã£ log")
                metrics = {
                    "mean_cv_accuracy": selected_run.data.metrics.get("mean_cv_accuracy", "N/A"),
                    "std_cv_accuracy": selected_run.data.metrics.get("std_cv_accuracy", "N/A"),
                    "accuracy": selected_run.data.metrics.get("accuracy", "N/A"),
                    "model_type": selected_run.data.metrics.get("model_type", "N/A"),
                    "kernel": selected_run.data.metrics.get("kernel", "N/A"),
                    "C_value": selected_run.data.metrics.get("C_value", "N/A")
                
                }
                st.json(metrics)
    
                # 5) NÃºt báº¥m má»Ÿ MLflow UI
                st.subheader("Truy cáº­p MLflow UI")
                mlflow_url = "https://dagshub.com/quangdinhhusc/HMVPYTHON.mlflow"
                if st.button("Má»Ÿ MLflow UI"):
                    st.markdown(f'**[Click Ä‘á»ƒ má»Ÿ MLflow UI]({mlflow_url})**')
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘Æ°á»£c log. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
    
        except Exception as e:
            st.error(f"KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i MLflow: {e}")

    




if __name__ == "__main__":
    run_PseudoLabellingt_app()
    
    